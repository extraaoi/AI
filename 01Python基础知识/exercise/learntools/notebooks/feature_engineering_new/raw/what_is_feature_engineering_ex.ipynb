{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In this first exercise, you'll do a complete iteration of feature development: understand the dataset, create a baseline model, create a derived feature, and compare performance.\n",
    "\n",
    "Run this next cell to set everything up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.feature_engineering_new.ex1 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "\n",
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Label encoding for categoricals\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(\n",
    "        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll work with the **Ames Housing** dataset to predict house prices based on information like the number oof bedrooms, number of bathrooms, and the year it was built.  You can find all of the datasets from this course [here](https://www.kaggle.com/ryanholbrook/fe-course-data).\n",
    "\n",
    "Run the next code cell to load and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/fe-course-data/ames.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective feature engineering makes use of prominent relationships in the dataset. Data visualization is one of the best ways to discover these relationships. Now you'll use Seaborn to discover some important things about the *Ames* data. (Check our our [Data Visualization](https://www.kaggle.com/learn/data-visualization) course, too!)\n",
    "\n",
    "You can see the relationship a feature has to the target with a *scatterplot*. Take a look at scatterplots for `YearBuilt` and `MoSold` relative to `SalePrice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "axs[0] = sns.scatterplot(x=\"YearBuilt\", y=\"SalePrice\", data=df, ax=axs[0])\n",
    "axs[1] = sns.scatterplot(x=\"MoSold\", y=\"SalePrice\", data=df, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Discover Relationships\n",
    "\n",
    "Does there appear to be a significant relationship between either feature and the target? If so, does the relationship appear to be linear (best fit with a line)?\n",
    "\n",
    "After you've thought about your answer, run the following cell for a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "The number of bathrooms in a home is often important to prospective home-buyers. The data contains four such features:\n",
    "- `FullBath`\n",
    "- `HalfBath`\n",
    "- `BsmtFullBath`\n",
    "- `BsmtHalfBath`\n",
    "\n",
    "# 2) Create a New Feature\n",
    "\n",
    "Create a new feature `TotalBaths` that describes the *total* number of bathrooms in a home. There are a couple answers that might be reasonable. Can you think of a way that's better than just summing the features up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X[\"TotalBaths\"] = ____\n",
    "\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X = df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "\n",
    "X[\"TotalBaths\"] = \\\n",
    "    df.FullBath + df.HalfBath + \\\n",
    "    df.BsmtFullBath + df.BsmtHalfBath\n",
    "\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X = df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "\n",
    "X[\"TotalBaths\"] = \\\n",
    "    df.FullBath + df.HalfBath\n",
    "\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X = df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "\n",
    "X[\"TotalBaths\"] = \\\n",
    "    df.BsmtFullBath + df.BsmtHalfBath\n",
    "\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X = df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "\n",
    "# Solution 1: HalfBath with half the weight of FullBath\n",
    "X[\"TotalBaths\"] = \\\n",
    "    df.FullBath + 0.5 * df.HalfBath + \\\n",
    "    df.BsmtFullBath + 0.5 * df.BsmtHalfBath\n",
    "\n",
    "# Solution 2: Same, but preserves int type\n",
    "X[\"TotalBaths\"] = \\\n",
    "    2 * df.FullBath + df.HalfBath + \\\n",
    "    2 * df.BsmtFullBath + df.BsmtHalfBath\n",
    "\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Now compare the performance of XGBoost with and without the `TotalBaths` feature. (The `score_dataset` function performs 5-fold cross-validation with XGBoost using with the RMSLE metric, the same metric used in the *House Prices* competition.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = df.copy()\n",
    "y_base = X_base.pop(\"SalePrice\")\n",
    "\n",
    "baseline_score = score_dataset(X_base, y_base)\n",
    "new_score = score_dataset(X, y)\n",
    "\n",
    "print(f\"Score Without New Feature: {baseline_score:.4f} RMSLE\")\n",
    "print(f\"Score With New Feature: {new_score:.4f} RMSLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Feature Selection\n",
    "\n",
    "Based on the performance of XGBoost with and without the additional feature, would you decide to keep or discard the new feature? Or is there not enough information to decide?\n",
    "\n",
    "After you've thought about you're answer, run the next cell for the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating on Feature Sets #\n",
    "\n",
    "You've just worked through a complete iteration of feature development: discovery, creation, validation, and selection. In most machine learning projects, you'll likely go through many such iterations before arriving at your final, best feature set.\n",
    "\n",
    "In the next lesson, you'll learn about *feature utility*, a way of scoring features for their potential usefulness -- a big help when you're just getting started with a new dataset!\n",
    "\n",
    "# Keep Going #\n",
    "\n",
    "[**Discover useful features**](#$NEXT_NOTEBOOK_URL$) with mutual information."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
